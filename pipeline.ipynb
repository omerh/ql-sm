{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.24.85-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m901.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sagemaker\n",
      "  Downloading sagemaker-2.110.0.tar.gz (576 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m576.0/576.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "Collecting botocore<1.28.0,>=1.27.85\n",
      "  Downloading botocore-1.27.85-py3-none-any.whl (9.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting attrs<22,>=20.3.0\n",
      "  Using cached attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "Collecting google-pasta\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting numpy<2.0,>=1.9.0\n",
      "  Using cached numpy-1.23.3-cp39-cp39-macosx_11_0_arm64.whl (13.4 MB)\n",
      "Collecting protobuf<4.0,>=3.1\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf3-to-dict<1.0,>=0.1.5\n",
      "  Using cached protobuf3_to_dict-0.1.5-py3-none-any.whl\n",
      "Collecting smdebug_rulesconfig==1.0.1\n",
      "  Using cached smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Collecting importlib-metadata<5.0,>=1.4.0\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from sagemaker) (21.3)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.5.0-cp39-cp39-macosx_11_0_arm64.whl (10.9 MB)\n",
      "Collecting pathos\n",
      "  Using cached pathos-0.2.9-py3-none-any.whl (76 kB)\n",
      "Collecting schema\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./venv/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.85->boto3) (2.8.2)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./venv/lib/python3.9/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.9/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.4-py2.py3-none-any.whl (500 kB)\n",
      "Collecting pox>=0.3.1\n",
      "  Using cached pox-0.3.1-py2.py3-none-any.whl (28 kB)\n",
      "Collecting dill>=0.3.5.1\n",
      "  Using cached dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "Collecting ppft>=1.7.6.5\n",
      "  Using cached ppft-1.7.6.5-py2.py3-none-any.whl (52 kB)\n",
      "Collecting multiprocess>=0.70.13\n",
      "  Using cached multiprocess-0.70.13-py39-none-any.whl (132 kB)\n",
      "Collecting contextlib2>=0.5.5\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.110.0-py2.py3-none-any.whl size=791645 sha256=9cd100d576896cac6cd70de7a548a114975cd0cbd1d4ad096cd91b9d77f7dfa1\n",
      "  Stored in directory: /Users/omerhaim/Library/Caches/pip/wheels/7a/91/b5/9283808394f1f0a239476c943327eb68d38c10a93d30aecfa8\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: pytz, zipp, urllib3, smdebug_rulesconfig, protobuf, ppft, pox, numpy, jmespath, google-pasta, dill, contextlib2, attrs, schema, protobuf3-to-dict, pandas, multiprocess, importlib-metadata, botocore, s3transfer, pathos, boto3, sagemaker\n",
      "Successfully installed attrs-21.4.0 boto3-1.24.85 botocore-1.27.85 contextlib2-21.6.0 dill-0.3.5.1 google-pasta-0.2.0 importlib-metadata-4.13.0 jmespath-1.0.1 multiprocess-0.70.13 numpy-1.23.3 pandas-1.5.0 pathos-0.2.9 pox-0.3.1 ppft-1.7.6.5 protobuf-3.20.3 protobuf3-to-dict-0.1.5 pytz-2022.4 s3transfer-0.6.0 sagemaker-2.110.0 schema-0.7.5 smdebug_rulesconfig-1.0.1 urllib3-1.26.12 zipp-3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 sagemaker\n",
    "\n",
    "\n",
    "project_name = \"tensorflow-project-A1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/omerhaim/work/aws/quicklizard-sagemaker\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu-west-1 910416587115 910416587115.dkr.ecr.eu-west-1.amazonaws.com /Users/omerhaim/work/aws/quicklizard-sagemaker\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "sm_session = sagemaker.Session()\n",
    "account_id = sm_session.account_id()\n",
    "region = sm_session._region_name\n",
    "bucket = sm_session.default_bucket() \n",
    "ecr_url = f\"{account_id}.dkr.ecr.{region}.amazonaws.com\"\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "print(region, account_id, ecr_url, base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building to docker image for BYOC processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: docker\n",
      "\n",
      "[Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "os.chdir(f\"{base_dir}/processingContainer\")\n",
    "\n",
    "repo_name='processing-byoc'\n",
    "version='v1'\n",
    "\n",
    "# create the repo in ECR\n",
    "!aws ecr describe-repositories --repository-names {repo_name} > /dev/null || aws ecr create-repository --repository-name {repo_name} > /dev/null\n",
    "\n",
    "# Build to custom image\n",
    "!aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {ecr_url}\n",
    "\n",
    "# If you use an x86 architecture workstation, than run native docker build for your BYC image\n",
    "#!docker build -t {ecr_url}/{repo_name}:{version} .\n",
    "#!docker push {ecr_url}/{repo_name}:{version}\n",
    "\n",
    "# If you are running on Mac M1 you need to build the BYC using buildx\n",
    "!docker buildx build --platform=linux/amd64 -t {ecr_url}/{repo_name}:{version} . --push\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing with your own container\n",
    "\n",
    "This uses a generic ScriptProcessor that runs your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name omer to get Role path.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "try:\n",
    "    execution_role = get_execution_role() # will work when running in sagemaker\n",
    "except ValueError:\n",
    "    execution_role = \"AmazonSageMaker-ExecutionRole-20210510T183593\" # on the local machine place the ARN manually\n",
    "\n",
    "# S3 input and output\n",
    "s3_npy_input_train_files = f\"s3://{bucket}/{project_name}/train/\"\n",
    "s3_npy_input_test_files = f\"s3://{bucket}/{project_name}/test/\"\n",
    "s3_parquet_output_files = f\"s3://{bucket}/{project_name}/parquet/\"\n",
    "\n",
    "# local processing path\n",
    "container_local_input_path = \"/opt/ml/processing/input/\"\n",
    "container_local_output_path = \"/opt/ml/processing/output/\"\n",
    "\n",
    "# create a generic script process that will run your processing to parquet files.\n",
    "processor = ScriptProcessor(\n",
    "    command=['python3'],\n",
    "    image_uri=f\"{ecr_url}/{repo_name}:{version}\",\n",
    "    role=execution_role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.xlarge',\n",
    "    env={\"sm_input\": container_local_input_path,\n",
    "         \"sm_output\": container_local_output_path}\n",
    "    )\n",
    "\n",
    "# Run the processing script and add input and output files, you can add as many as you want\n",
    "processor.run(code='./scripts/process.py',\n",
    "    inputs=[ProcessingInput(\n",
    "        source=s3_npy_input_train_files,\n",
    "        destination=container_local_input_path)],\n",
    "    outputs=[ProcessingOutput(\n",
    "        source=container_local_output_path,\n",
    "        destination=s3_parquet_output_files)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the training container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: docker\n",
      "\n",
      "[Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "os.chdir(f\"{base_dir}/trainingContainer\")\n",
    "\n",
    "training_repo_name='training-byoc'\n",
    "version='v1'\n",
    "\n",
    "# create the repo in ECR\n",
    "!aws ecr describe-repositories --repository-names {training_repo_name} > /dev/null || aws ecr create-repository --repository-name {training_repo_name} > /dev/null\n",
    "\n",
    "# Build to custom image\n",
    "!aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {ecr_url}\n",
    "\n",
    "# If you use an x86 architecture workstation, than run native docker build for your BYC image\n",
    "#!docker build -t {ecr_url}/{repo_name}:{version} .\n",
    "#!docker push {ecr_url}/{repo_name}:{version}\n",
    "\n",
    "# If you are running on Mac M1 you need to build the BYC using buildx\n",
    "!docker buildx build --platform=linux/amd64 -t {ecr_url}/{training_repo_name}:{version} . --push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This uses a generic Estimator as its a BYOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a training job, save the model according to `SM_MODEL_DIR` environment variable. SageMaker will take what is in the local directory, it will compress it using tar.gz and upload it to S3, then the `estimator` object will have the output location of the model in S3 for the next step of offline processing job for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-04 14:10:18 Starting - Starting the training job...\n",
      "2022-10-04 14:10:42 Starting - Preparing the instances for trainingProfilerReport-1664892617: InProgress\n",
      "......\n",
      "2022-10-04 14:11:42 Downloading - Downloading input data...\n",
      "2022-10-04 14:12:22 Training - Downloading the training image...\n",
      "2022-10-04 14:12:57 Uploading - Uploading generated training model\u001b[34m2022-10-04 14:12:44,276 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:44,290 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:44,304 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:44,318 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.c5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 128,\n",
      "        \"epochs\": 15,\n",
      "        \"learning_rate\": 0.01\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.c5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"ql-byoc-2022-10-04-14-10-15-979\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-910416587115/ql-byoc-2022-10-04-14-10-15-979/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":128,\"epochs\":15,\"learning_rate\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.c5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-910416587115/ql-byoc-2022-10-04-14-10-15-979/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.c5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":15,\"learning_rate\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"ql-byoc-2022-10-04-14-10-15-979\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-910416587115/ql-byoc-2022-10-04-14-10-15-979/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"15\",\"--learning_rate\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=128\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python39.zip:/usr/local/lib/python3.9:/usr/local/lib/python3.9/lib-dynload:/usr/local/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python train.py --batch_size 128 --epochs 15 --learning_rate 0.01\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:44,318 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:44.380347: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:44.869307: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:44.869333: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:44.942098: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:46.585305: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:46.585393: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:46.585402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\u001b[0m\n",
      "\u001b[34mstarting to train\u001b[0m\n",
      "\u001b[34mparsing args\u001b[0m\n",
      "\u001b[34mstarting to train\u001b[0m\n",
      "\u001b[34mStarting Training script...\u001b[0m\n",
      "\u001b[34mTensorflow version 2.10.0\u001b[0m\n",
      "\u001b[34mDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\u001b[0m\n",
      "\u001b[34m#015 8192/57026 [===>..........................] - ETA: 0s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01557026/57026 [==============================] - 0s 0us/step\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:50.191101: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:50.191789: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:50.191826: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-229-174.eu-west-1.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:50.196060: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mINPUT FILE LIST: \u001b[0m\n",
      "\u001b[34m['/opt/ml/code/../data/raw/y_train.npy', '/opt/ml/code/../data/raw/x_test.npy', '/opt/ml/code/../data/raw/x_train.npy', '/opt/ml/code/../data/raw/y_test.npy']\u001b[0m\n",
      "\u001b[34mSAVED LABEL TRAINING DATA FILE\u001b[0m\n",
      "\u001b[34mSAVED TRANSFORMED TEST DATA FILE\u001b[0m\n",
      "\u001b[34mSAVED TRANSFORMED TRAINING DATA FILE\u001b[0m\n",
      "\u001b[34mSAVED LABEL TEST DATA FILE\u001b[0m\n",
      "\u001b[34mx train (404, 13) y train (404,)\u001b[0m\n",
      "\u001b[34mx test (102, 13) y test (102,)\u001b[0m\n",
      "\u001b[34m/cpu:0\u001b[0m\n",
      "\u001b[34mbatch_size = 128, epochs = 15, learning rate = 0.01\u001b[0m\n",
      "\u001b[34mEpoch 1/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 1s - loss: 625.2939#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 1s 43ms/step - loss: 551.7028 - val_loss: 446.0011\u001b[0m\n",
      "\u001b[34mEpoch 2/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 452.2627#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 9ms/step - loss: 375.7928 - val_loss: 279.5653\u001b[0m\n",
      "\u001b[34mEpoch 3/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 251.9480#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 9ms/step - loss: 225.4053 - val_loss: 153.7305\u001b[0m\n",
      "\u001b[34mEpoch 4/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 151.7563#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 7ms/step - loss: 125.3228 - val_loss: 92.4759\u001b[0m\n",
      "\u001b[34mEpoch 5/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 101.8120#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 16ms/step - loss: 81.8267 - val_loss: 68.5004\u001b[0m\n",
      "\u001b[34mEpoch 6/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 55.8816#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 7ms/step - loss: 65.5897 - val_loss: 58.7432\u001b[0m\n",
      "\u001b[34mEpoch 7/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 72.6504#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 7ms/step - loss: 59.0295 - val_loss: 52.8173\u001b[0m\n",
      "\u001b[34mEpoch 8/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 64.9685#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 7ms/step - loss: 54.3656 - val_loss: 49.5970\u001b[0m\n",
      "\u001b[34mEpoch 9/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 45.1411#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 7ms/step - loss: 52.0704 - val_loss: 47.0849\u001b[0m\n",
      "\u001b[34mEpoch 10/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 57.3847#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 7ms/step - loss: 49.9716 - val_loss: 44.0383\u001b[0m\n",
      "\u001b[34mEpoch 11/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 48.8768#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 6ms/step - loss: 47.7321 - val_loss: 41.9211\u001b[0m\n",
      "\u001b[34mEpoch 12/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 55.3780#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 9ms/step - loss: 46.3834 - val_loss: 39.5147\u001b[0m\n",
      "\u001b[34mEpoch 13/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 40.2147#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 9ms/step - loss: 43.7305 - val_loss: 38.4042\u001b[0m\n",
      "\u001b[34mEpoch 14/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 35.5971#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 13ms/step - loss: 41.9895 - val_loss: 36.8254\u001b[0m\n",
      "\u001b[34mEpoch 15/15\u001b[0m\n",
      "\u001b[34m#0151/4 [======>.......................] - ETA: 0s - loss: 40.5431#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0154/4 [==============================] - 0s 7ms/step - loss: 40.2657 - val_loss: 36.6691\u001b[0m\n",
      "\u001b[34m1/1 - 0s - loss: 36.6691 - 15ms/epoch - 15ms/step\u001b[0m\n",
      "\u001b[34mTest MSE : 36.6690559387207\u001b[0m\n",
      "\u001b[34m2022-10-04 14:12:52,753 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-10-04 14:13:22 Completed - Training job completed\n",
      "Training seconds: 98\n",
      "Billable seconds: 98\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# hyperparameters will be added as command line arguments to the script command, and we will use argparse to use them. SageMaker SDK will parse and add them to the train command.\n",
    "hyperparameters = {'epochs': 15, 'batch_size': 128, 'learning_rate': 0.01 }\n",
    "\n",
    "# This is a generic estimator for running training on your own containers.\n",
    "estimator = Estimator(\n",
    "    source_dir='scripts', # adding source_dir will upload the entire directory\n",
    "    entry_point='train.py',\n",
    "    instance_type='ml.c5.xlarge',\n",
    "    instance_count=1,\n",
    "    hyperparameters=hyperparameters,\n",
    "    role='arn:aws:iam::910416587115:role/service-role/AmazonSageMaker-ExecutionRole-20210510T183593',\n",
    "    base_job_name='ql-byoc',\n",
    "    image_uri=f\"{ecr_url}/{training_repo_name}:{version}\"\n",
    "    )\n",
    "\n",
    "# define the inputs for the train and test\n",
    "inputs = {'train': s3_npy_input_train_files, 'test': s3_npy_input_test_files}\n",
    "\n",
    "# submit a training job\n",
    "estimator.fit(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-910416587115/ql-byoc-2022-10-04-14-10-15-979/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# The estimator holds the S3 path where it uploaded the model from the training container according to the SM_MODEL_DIR environment variable.\n",
    "print(estimator.model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model, we can run a generic processing job on your built-in processing container, and run the inference.\n",
    "In my sample I will run `model.evaluate` as I would do inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  processing-byoc-2022-10-04-14-45-57-596\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-eu-west-1-910416587115/tensorflow-project-A1/test/', 'LocalPath': '/opt/ml/processing/input/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-eu-west-1-910416587115/ql-byoc-2022-10-04-14-10-15-979/output/model.tar.gz', 'LocalPath': '/opt/ml/processing/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-eu-west-1-910416587115/processing-byoc-2022-10-04-14-45-57-596/input/code/offline-inference.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'output-1', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-eu-west-1-910416587115/tensorflow-project-A1/results', 'LocalPath': '/opt/ml/processing/output/', 'S3UploadMode': 'EndOfJob'}}]\n",
      "........................\n",
      "\u001b[34m2022-10-04 14:50:02.341817: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2022-10-04 14:50:02.474738: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-10-04 14:50:02.474769: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2022-10-04 14:50:02.502969: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[0m\n",
      "\u001b[34m2022-10-04 14:50:03.326560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-10-04 14:50:03.326669: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-10-04 14:50:03.326683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\u001b[0m\n",
      "\u001b[34m2022-10-04 14:50:05.335382: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-10-04 14:50:05.335413: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2022-10-04 14:50:05.335435: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-72-253.eu-west-1.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2022-10-04 14:50:05.336092: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m4/4 - 0s - loss: 36.6691 - 166ms/epoch - 41ms/step\u001b[0m\n",
      "\u001b[34mTest MSE : 36.6690559387207\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "container_local_model_path = '/opt/ml/processing/model' # The file path must start with /opt/ml/processing/ \n",
    "s3_inference_result_path = f\"s3://{bucket}/{project_name}/results\" # upload the evaluate result to this s3 path, the same as it will do for inference results in our case.\n",
    "\n",
    "# again, a generic script processor that has all needed dependencies installed to run inference.\n",
    "processor = ScriptProcessor(\n",
    "    command=['python3'],\n",
    "    image_uri=f\"{ecr_url}/{repo_name}:{version}\",\n",
    "    role=execution_role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.c5.xlarge',\n",
    "    env={\"sm_input\": container_local_input_path,\n",
    "         \"sm_output\": container_local_output_path,\n",
    "         \"sm_model\": container_local_model_path}\n",
    "    )\n",
    "\n",
    "# call the processing job to run the offline processing using the offline inference script\n",
    "# note that there are 2 inputs, one for the mode, and the other for the data to use for evaluating (the same as you will do for inference)\n",
    "processor.run(\n",
    "    code='./scripts/offline-inference.py',\n",
    "    inputs=[ProcessingInput(\n",
    "                source=s3_npy_input_test_files, # I will download the test files as input files for the model\n",
    "                destination=container_local_input_path),\n",
    "            ProcessingInput(\n",
    "                source=estimator.model_data,\n",
    "                destination=container_local_model_path\n",
    "                )\n",
    "            ],\n",
    "    outputs=[ProcessingOutput(\n",
    "        source=container_local_output_path,\n",
    "        destination=s3_inference_result_path)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the pipeline from the above steps\n",
    "\n",
    "The pipeline will be: Processing job to Generate Parquet files -> Training job to Train -> Processing job to Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b97556f955fa7ea3ee5447f7cbd5d37ccf23eea5bf286078bbac1c059f2a26ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
